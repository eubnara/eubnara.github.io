<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Hadoop | EUB's second brain</title>
<meta name=keywords content><meta name=description content="Contains posts related to Hadoop"><meta name=author content><link rel=canonical href=https://eubnara.github.io/computer-science/hadoop/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://eubnara.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://eubnara.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://eubnara.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://eubnara.github.io/apple-touch-icon.png><link rel=mask-icon href=https://eubnara.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://eubnara.github.io/computer-science/hadoop/index.xml><link rel=alternate hreflang=en href=https://eubnara.github.io/computer-science/hadoop/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-5436088801258740" crossorigin=anonymous></script><meta property="og:title" content="Hadoop"><meta property="og:description" content="Contains posts related to Hadoop"><meta property="og:type" content="website"><meta property="og:url" content="https://eubnara.github.io/computer-science/hadoop/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Hadoop"><meta name=twitter:description content="Contains posts related to Hadoop"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Computer science","item":"https://eubnara.github.io/computer-science/"},{"@type":"ListItem","position":2,"name":"Hadoop","item":"https://eubnara.github.io/computer-science/hadoop/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://eubnara.github.io/ accesskey=h title="EUB's second brain (Alt + H)">EUB's second brain</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://eubnara.github.io/about title=About><span>About</span></a></li><li><a href=https://eubnara.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://eubnara.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://eubnara.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://eubnara.github.io/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><header class=page-header><h1>Hadoop</h1><div class=post-description>Contains posts related to Hadoop</div></header><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Don't sync privileges from ranger to hive</h2></header><div class=entry-content><p>When Apache Ranger is configured for authorization on Secure Hadoop cluster, Hive below 4.x.x synchronizes all the ranger hive policies to rdbms for Hive as default. It is unnecessary and make unnecessary high load on db. See https://issues.apache.org/jira/browse/HIVE-25391. You can disable it with the configurations on HiveServer2 as follows.
hive.privilege.synchronizer=false</p></div><footer class=entry-footer><span title='2024-10-19 16:26:00 +0900 +0900'>October 19, 2024</span></footer><a class=entry-link aria-label="post link to Don't sync privileges from ranger to hive" href=https://eubnara.github.io/computer-science/hadoop/dont-sync-privileges-from-ranger-to-hive/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Monitoring metrics related to "jute.maxbuffer"</h2></header><div class=entry-content><p>There is a configuration named as “jute.maxbuffer” when using zookeeper. This can be set on zookeeper client side or server side. On zookeeper client side, the setting should be lower than that on zookeeper server. If a client gets data bigger than the setting, it will get an error.
There are some related issue.
https://issues.apache.org/jira/browse/HIVE-21993 https://issues.apache.org/jira/browse/YARN-2962 In order to avoid this errors. Some metrics should be monitored on zookeeper.
last_client_response_size or max_client_response_size client_response_size is a response size in bytes from zookeeper server to client. last_proposal_size or max_proposal_size proposal_size is a proposal size in bytes from zookeeper server leader to follower. proposal?: refer to https://zookeeper.apache.org/doc/r3.7.1/zookeeperInternals.html. These values should be lower than jute.maxbuffer. This setting can be set through jvm argument like -Djute.maxbuffer=10485760 (10mb).
...</p></div><footer class=entry-footer><span title='2024-05-25 22:34:00 +0900 +0900'>May 25, 2024</span></footer><a class=entry-link aria-label='post link to Monitoring metrics related to "jute.maxbuffer"' href=https://eubnara.github.io/computer-science/hadoop/monitoring-jute.maxbuffer/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Checklist for hive metastore when using mysql</h2></header><div class=entry-content><p>MySQL Index There are some expensive operations for hive metastore when accessing or storing metadatas on RDBMS.
Here are some official hive patches for indexing.
-- HIVE-21063 CREATE UNIQUE INDEX `NOTIFICATION_LOG_EVENT_ID` ON NOTIFICATION_LOG (`EVENT_ID`) USING BTREE; -- HIVE-21487 CREATE INDEX COMPLETED_COMPACTIONS_RES ON COMPLETED_COMPACTIONS (CC_DATABASE,CC_TABLE,CC_PARTITION); -- HIVE-27165 DROP INDEX TAB_COL_STATS_IDX ON TAB_COL_STATS; CREATE INDEX TAB_COL_STATS_IDX ON TAB_COL_STATS (DB_NAME, TABLE_NAME, COLUMN_NAME, CAT_NAME) USING BTREE; DROP INDEX PCS_STATS_IDX ON PART_COL_STATS; CREATE INDEX PCS_STATS_IDX ON PART_COL_STATS (DB_NAME,TABLE_NAME,COLUMN_NAME,PARTITION_NAME,CAT_NAME) USING BTREE; When you upgrade your hive, there are some changes on tables in rdbms. You can find needed SQLs depending on version at https://github.com/apache/hive/tree/master/standalone-metastore/metastore-server/src/main/sql/mysql.
...</p></div><footer class=entry-footer><span title='2023-10-12 08:34:00 +0900 +0900'>October 12, 2023</span></footer><a class=entry-link aria-label="post link to Checklist for hive metastore when using mysql" href=https://eubnara.github.io/computer-science/hadoop/hivemetastore-mysql/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Some cases where "rdns = false" in krb5.conf does not work in Hadoop ecosystem</h2></header><div class=entry-content><p>https://web.mit.edu/kerberos/krb5-1.13/doc/admin/princ_dns.html
Operating system bugs may prevent a setting of rdns = false from disabling reverse DNS lookup. Some versions of GNU libc have a bug in getaddrinfo() that cause them to look up PTR records even when not required. MIT Kerberos releases krb5-1.10.2 and newer have a workaround for this problem, as does the krb5-1.9.x series as of release krb5-1.9.4.
There are some cases where “rdns = false” in krb5.conf is not respected in Hadoop ecosystem. You can try to modify /etc/hosts or register PTR records to fix this kind of issues.
...</p></div><footer class=entry-footer><span title='2023-07-02 18:48:00 +0900 +0900'>July 2, 2023</span></footer><a class=entry-link aria-label='post link to Some cases where "rdns = false" in krb5.conf does not work in Hadoop ecosystem' href=https://eubnara.github.io/computer-science/hadoop/rdns-false-not-work/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Hadoop commands</h2></header><div class=entry-content><p>HDFS Reconfigure without restart https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html
configurable keys are limited without restart $ hdfs dfsadmin -reconfig namenode nn1.example.com:8020 properties Node [nn1.example.com:8020] Reconfigurable properties: dfs.block.placement.ec.classname dfs.block.replicator.classname dfs.heartbeat.interval dfs.image.parallel.load dfs.namenode.avoid.read.slow.datanode dfs.namenode.block-placement-policy.exclude-slow-nodes.enabled dfs.namenode.heartbeat.recheck-interval dfs.namenode.max.slowpeer.collect.nodes dfs.namenode.replication.max-streams dfs.namenode.replication.max-streams-hard-limit dfs.namenode.replication.work.multiplier.per.iteration dfs.storage.policy.satisfier.mode fs.protected.directories hadoop.caller.context.enabled ipc.8020.backoff.enable</p></div><footer class=entry-footer><span title='2023-02-05 17:02:26 +0900 +0900'>February 5, 2023</span></footer><a class=entry-link aria-label="post link to Hadoop commands" href=https://eubnara.github.io/computer-science/hadoop/commands/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>About "HADOOP_CLASSPATH" environment variable</h2></header><div class=entry-content><p>https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/UnixShellGuide.html#HADOOP_CLASSPATH In Hadoop ecosystem, HADOOP_CLASSPATH environment variable is commonly used in many places. Hive is use this variable, too. I wonder that how the HADOOP_CLASSPATH variable is used in a script like beeline. I cannot find HADOOP_CLASSPATH variable in Hive source codes. I finally figure out that when executing beeline it uses hadoop jar command. (https://github.com/apache/hive/blob/rel/release-3.1.3/bin/ext/beeline.sh#L35) It uses RunJar.java where HADOOP_CLASSPATH is used to set CLASSPATH. (https://github.com/apache/hadoop/blob/rel/release-3.3.4/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/util/RunJar.java#L347-L351)
If something in Hadoop ecosystem uses RunJar#main, it probably repect HADOOP_CLASSPATH environment variable.
...</p></div><footer class=entry-footer><span title='2023-02-05 16:54:58 +0900 +0900'>February 5, 2023</span></footer><a class=entry-link aria-label='post link to About "HADOOP_CLASSPATH" environment variable' href=https://eubnara.github.io/computer-science/hadoop/hadoop-classpath/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>SPNEGO-enabled Hadoop DataNode misjudges kerberos "replay attack".</h2></header><div class=entry-content><p>references https://docs.cloudera.com/cloudera-manager/7.5.5/security-troubleshooting/cm-security-troubleshooting.pdf https://search-guard.com/elasticsearch-kibana-kerberos/ I guess that this is caused by sharing the same kerberos keytab (/etc/security/keytabs/spnego.service.keytab) and principal(HTTP/_HOST@{REALM}) among Hadoop daemons (NameNode, DataNode, JournalNodes, ResourceManager, NodeManager …). I assume that DataNode misjudges it is a replay attack in certain circumstances.
Adding the following jvm system properties to Hadoop daemons will fix this issue as a workaround. It means java process will not use replay cache.
-Dsun.security.krb5.rcache=none</p></div><footer class=entry-footer><span title='2023-02-05 16:01:17 +0900 +0900'>February 5, 2023</span></footer><a class=entry-link aria-label='post link to SPNEGO-enabled Hadoop DataNode misjudges kerberos "replay attack".' href=https://eubnara.github.io/computer-science/hadoop/spnego-request-is-a-replay/></a></article></main><footer class=footer><span>&copy; 2024 <a href=https://eubnara.github.io/>EUB's second brain</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>